# Autonomous Data Pipeline

데이터(이미지/동영상)와 메타데이터를 받아 저장·관리·기본 처리를 제공하는 백엔드 서버입니다.  
모델 추론이나 복잡한 라벨링 없이 “수집→저장→검증/전처리→조회/통계→내보내기”에 집중합니다.

## 핵심 요구사항
- 업로드: 단일 파일(이미지/동영상) + 메타데이터를 동기 처리해 저장하고 검증/전처리 수행
- 조회: 메타데이터(차량 ID, 촬영 시각 등) 및 품질(예: 블러) 기준 필터/페이징
- 다운로드: 필터 조건으로 묶은 데이터 서브셋을 ZIP으로 내보내기
- 통계: 메타데이터/품질 기반 집계 제공
- 스토리지: 기본 로컬, 향후 확장을 위해 MinIO(S3 호환) 옵션 유지
- 대량 트래픽 대비: 이후 배치(zip) 업로드, 메시지 큐 기반 비동기 처리/알림(설계만)

## API 계획 (v0)
- `POST /api/upload` : 단일 파일 + 메타데이터 업로드, 동기 전처리/검증 후 저장·DB 기록
- `POST /api/upload/batch` : ZIP 배치 업로드(대량 시 사용) — 추후 메시지 큐 연계 준비
- `GET /api/files` : 메타/품질 필터 + 페이징 조회
- `GET /api/files/{id}` : 단건 상세 조회
- `GET /api/download/dataset` : 조건 기반 ZIP 내보내기 (로컬 스토리지 지원)
- `GET /api/stats` : 기본 통계(개수, 메타 분포, 품질 요약)
- `GET /health` : 헬스 체크

## 데이터 모델 초안
- `files` : 저장 경로(원본/전처리), 타입(img/video), 크기, 해시, 메타데이터(JSON), 품질/검증 결과
- `datasets` : 내보내기/버전 관리용 번들 메타
- `processing_jobs` : (후속) 비동기 처리/알림 상태 추적

## 전처리/검증 (동기)
- 이미지: 리사이즈·정규화, 블러 스코어, 포맷/크기 검사
- 동영상: 포맷/길이/프레임샘플 메타 검사(간단 메타 읽기부터 시작)
- 메타데이터 필수 검증(예: vehicle_id, captured_at)

## 스토리지
- 기본 로컬 디렉터리
- 옵션: MinIO(S3)로 전환 가능하도록 어댑터 유지

## 기술 스택
- Python, FastAPI
- PostgreSQL (메타데이터)
- 로컬 파일시스템 / MinIO (파일 저장)
- OpenCV (이미지/동영상 메타 처리), Pillow, NumPy
- Alembic (마이그레이션), Pytest (테스트)

## 진행 단계
1) 스키마/설정 정리 → 2) 업로드/저장/검증/전처리 구현 → 3) 조회/다운로드/통계 API → 4) 배치 업로드/비동기 처리 설계 → 5) 테스트/문서화
